{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efef5571-7315-42eb-9c9b-8fb2d2658716",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32598af6-a5c2-4a19-b55f-e3c17097402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import altair as alt\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb4084-d25e-4185-8098-fa1429b31f4b",
   "metadata": {},
   "source": [
    "# Functions  \n",
    "\n",
    "I will define some functions to avoid repetation in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb6afc8-8a13-44e0-b84f-8e8bb5605bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_datetime_zone(df):\n",
    "    df = datetime.strptime(df, \"%Y-%m-%d %H:%M:%S\")\n",
    "    hour_diff = timedelta(hours=3)\n",
    "    df = df + hour_diff\n",
    "    return df\n",
    "\n",
    "def raw_date_to_datetime(raw_date):\n",
    "    datetime_dict = dict()  # New row to replace\n",
    "    datetime_dict[\"Date\"] = raw_date  # Get the date in the format \"DD.MM.YYYY\"\n",
    "    # datetime_dict[\"Time\"] = raw_date.strftime(\"%H:%M\")  # Get the time in format \"HH:MM\"\n",
    "    datetime_dict[\"MonthName\"] = raw_date.strftime(\"%B\")  # Get the full month name\n",
    "    datetime_dict[\"DayName\"] = raw_date.strftime(\"%A\")  # Get the full day name\n",
    "\n",
    "    return datetime_dict\n",
    "\n",
    "def ceil_dt(dt, delta):\n",
    "    dt_min = datetime.min.replace(tzinfo=dt.tzinfo)\n",
    "    return dt + (dt_min - dt) % delta\n",
    "\n",
    "def floor_dt(dt, delta):\n",
    "    replace = (dt.minute // delta) * delta\n",
    "    return dt.replace(minute=replace)\n",
    "\n",
    "def is_subscribed_to(subreddit_name, subscribed_subs_df):\n",
    "    return (subscribed_subs_df == subreddit_name).any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5ff07-6d4d-4d89-bc28-74acc258670c",
   "metadata": {},
   "source": [
    "# Data Collecting\n",
    "\n",
    "Get the data from the .csv files, clear and format a bit to get useful pandas DataFrames.  \n",
    "\n",
    "## Different Data\n",
    "* Subscribed Subreddits\n",
    "* IP Logs\n",
    "* Post Votes\n",
    "* Comment Votes\n",
    "* Posts\n",
    "* Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7196d180-f678-4694-b44d-478b47b44554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "data_path = \"./data/scrapped_data/\"\n",
    "backup_data_path = \"./data/raw_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7134578-d757-4fa4-95fe-aa3fb2106d70",
   "metadata": {},
   "source": [
    "## Subscribed Subreddits\n",
    "\n",
    "This data holds the subreddits that I am _currently_ subscribed to. It does not hold a history or any temporal data.  \n",
    "\n",
    "Reddit subreddits doesn't include direct a way to _categorize_ them by some kind of a tag or topic system execpt a list of _\"flairs\"_ that can be used to label posts in that subreddit. However, to better analyse them a tag system might be useful. I will use a google form to ask people to annotate the subreddits and use that data to categorize them.\n",
    "This data file also includes followed users (not subs). They are marked with a 'u_' prefix in the data. They will be filtered, but saved anyway since they might be useful in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733d3b3f-aa5c-4a5f-afe6-9d54c1a8f1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>Flairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskScienceFiction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CodeBullet</td>\n",
       "      <td>meme, question for codebullet, video idea, oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DMAcademy</td>\n",
       "      <td>offering advice, need advice: encounters &amp; adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DaystromInstitute</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepspaceninememes</td>\n",
       "      <td>original content [oc], shitpost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElectroBOOM</td>\n",
       "      <td>faf - rectify, electroboom question, non-elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExposurePorn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FATErpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GeekyaparLamers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GreekMythology</td>\n",
       "      <td>discussion, question, art, culture, history, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GuessTheMovie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KaderOyunu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MontyPythonMemes</td>\n",
       "      <td>oc, repost, crosspost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MovieQuotes</td>\n",
       "      <td>movie quote, tv quote, spoiler, nsfw, tearjerk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MrData</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Percabeth</td>\n",
       "      <td>percabeth things, pjotv, fan art, fanfiction, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PercyJacksonMemes</td>\n",
       "      <td>general book meme, percy jackson and the olymp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ProgrammerHumor</td>\n",
       "      <td>instanceof trend, meme, advanced, competition,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Python</td>\n",
       "      <td>beginner showcase, intermediate showcase, news...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PythonJobs</td>\n",
       "      <td>for hire, hiring, discussion, scam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SatisfactoryGame</td>\n",
       "      <td>discussion, guide, question, help, bug, crash ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ScarySigns</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SenNeDiyon</td>\n",
       "      <td>bi şeyler, meme, youtube, bvs seviyorum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TheLastAirbender</td>\n",
       "      <td>discussion, comics/books, cosplay, fan art, oc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TheLibrarians</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TheNewestOlympian</td>\n",
       "      <td>mike spoiler: don't read, news, discussion, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ubuntu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>UnexpectedSeinfeld</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>boardgames</td>\n",
       "      <td>review, session, news, rules, rules [answered]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>camphalfblood</td>\n",
       "      <td>discussion, analysis , merchandise, theory, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>consolerepair</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>datasets</td>\n",
       "      <td>request, resource, question, dataset, api, dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>django</td>\n",
       "      <td>apps, admin, article, channels, django cms, e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>djangolearning</td>\n",
       "      <td>i need help - troubleshooting, i need help - q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gaming</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>geek</td>\n",
       "      <td>tech/gadgets, film/tv/video games, books/artic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>learnprogramming</td>\n",
       "      <td>debugging, solved, tutorial, resource, topic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mathmemes</td>\n",
       "      <td>learning, bad math, notations, math pun, the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>montypython</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>movies</td>\n",
       "      <td>news, discussion, trailer, poster, article, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>projecteuler</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pythontips</td>\n",
       "      <td>module, syntax, meta, data_science, algorithms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>risa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>satisfactory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>seinfeld</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>seinfeldgifs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>startrek</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>startrekmemes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>thenextgeneration</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ubuntucinnamon</td>\n",
       "      <td>bug, review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>unexpectedMontyPython</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>unexpectedpython</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>veYakinEvren</td>\n",
       "      <td>yatay bakış, yayın kesiti, i̇zlerken konuş, oy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>yugioh</td>\n",
       "      <td>anime/manga, discussion, image, link, news, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                subreddit                                             Flairs\n",
       "0       AskScienceFiction                                                NaN\n",
       "1              CodeBullet  meme, question for codebullet, video idea, oth...\n",
       "2               DMAcademy  offering advice, need advice: encounters & adv...\n",
       "3       DaystromInstitute                                                NaN\n",
       "4      Deepspaceninememes                    original content [oc], shitpost\n",
       "5             ElectroBOOM  faf - rectify, electroboom question, non-elect...\n",
       "6            ExposurePorn                                                NaN\n",
       "7                 FATErpg                                                NaN\n",
       "8         GeekyaparLamers                                                NaN\n",
       "9          GreekMythology  discussion, question, art, culture, history, i...\n",
       "10          GuessTheMovie                                                NaN\n",
       "11             KaderOyunu                                                NaN\n",
       "12       MontyPythonMemes                              oc, repost, crosspost\n",
       "13            MovieQuotes  movie quote, tv quote, spoiler, nsfw, tearjerk...\n",
       "14                 MrData                                                NaN\n",
       "15              Percabeth  percabeth things, pjotv, fan art, fanfiction, ...\n",
       "16      PercyJacksonMemes  general book meme, percy jackson and the olymp...\n",
       "17        ProgrammerHumor  instanceof trend, meme, advanced, competition,...\n",
       "18                 Python  beginner showcase, intermediate showcase, news...\n",
       "19             PythonJobs                 for hire, hiring, discussion, scam\n",
       "20       SatisfactoryGame  discussion, guide, question, help, bug, crash ...\n",
       "21             ScarySigns                                                NaN\n",
       "22             SenNeDiyon            bi şeyler, meme, youtube, bvs seviyorum\n",
       "23       TheLastAirbender  discussion, comics/books, cosplay, fan art, oc...\n",
       "24          TheLibrarians                                                NaN\n",
       "25      TheNewestOlympian  mike spoiler: don't read, news, discussion, me...\n",
       "26                 Ubuntu                                                NaN\n",
       "27     UnexpectedSeinfeld                                                NaN\n",
       "28             boardgames  review, session, news, rules, rules [answered]...\n",
       "29          camphalfblood  discussion, analysis , merchandise, theory, he...\n",
       "30          consolerepair                                                NaN\n",
       "31               datasets  request, resource, question, dataset, api, dis...\n",
       "32                 django  apps, admin, article, channels, django cms, e-...\n",
       "33         djangolearning  i need help - troubleshooting, i need help - q...\n",
       "34                 gaming                                                NaN\n",
       "35                   geek  tech/gadgets, film/tv/video games, books/artic...\n",
       "36       learnprogramming  debugging, solved, tutorial, resource, topic, ...\n",
       "37              mathmemes  learning, bad math, notations, math pun, the e...\n",
       "38            montypython                                                NaN\n",
       "39                 movies  news, discussion, trailer, poster, article, me...\n",
       "40           projecteuler                                                NaN\n",
       "41             pythontips  module, syntax, meta, data_science, algorithms...\n",
       "42                   risa                                                NaN\n",
       "43           satisfactory                                                NaN\n",
       "44               seinfeld                                                NaN\n",
       "45           seinfeldgifs                                                NaN\n",
       "46               startrek                                                NaN\n",
       "47          startrekmemes                                                NaN\n",
       "48      thenextgeneration                                                NaN\n",
       "52         ubuntucinnamon                                        bug, review\n",
       "53  unexpectedMontyPython                                                NaN\n",
       "54       unexpectedpython                                                NaN\n",
       "55           veYakinEvren  yatay bakış, yayın kesiti, i̇zlerken konuş, oy...\n",
       "56                 yugioh  anime/manga, discussion, image, link, news, pr..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file, sort by name of the subreddits and reset the index after sorting\n",
    "sub_fname = \"subscribed_subreddits.csv\"\n",
    "subreddits_df = pd.read_csv(data_path + sub_fname).sort_values(by=\"subreddit\").reset_index().drop(columns=\"index\")\n",
    "\n",
    "followed_users_df = subreddits_df[subreddits_df[\"subreddit\"].str.contains(\"u_\")]\n",
    "subreddits_df = subreddits_df[~subreddits_df[\"subreddit\"].str.contains(\"u_\")]\n",
    "# subreddits_df.to_csv(data_path + sub_fname, index=False)\n",
    "subreddits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98027d16-8437-4cb0-98b2-c58edc0a9d94",
   "metadata": {},
   "source": [
    "## IP Logs\n",
    "\n",
    "IP logs data holds information about my logins to Reddit. It holds the datetime and the IP that I used. This data might be used on showing my active times even though it doesn't hold information on how long I have stayed active.  \n",
    "\n",
    "The date data is in the form of \"yyyy-mm-dd hh:mm:ss UTC\". I will convert time into GMT+3, and name the months and days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65de18df-5feb-4307-bfa5-2ea643aee4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MonthName</th>\n",
       "      <th>DayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-29 13:16:07</td>\n",
       "      <td>June</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-29 17:25:25</td>\n",
       "      <td>June</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-30 04:16:29</td>\n",
       "      <td>June</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-30 07:15:35</td>\n",
       "      <td>June</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-30 08:46:19</td>\n",
       "      <td>June</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2023-10-06 15:19:55</td>\n",
       "      <td>October</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2023-10-06 16:40:52</td>\n",
       "      <td>October</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2023-10-06 18:16:58</td>\n",
       "      <td>October</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2023-10-07 11:04:02</td>\n",
       "      <td>October</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2023-10-07 12:05:24</td>\n",
       "      <td>October</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Date MonthName   DayName\n",
       "0   2023-06-29 13:16:07      June  Thursday\n",
       "1   2023-06-29 17:25:25      June  Thursday\n",
       "2   2023-06-30 04:16:29      June    Friday\n",
       "3   2023-06-30 07:15:35      June    Friday\n",
       "4   2023-06-30 08:46:19      June    Friday\n",
       "..                  ...       ...       ...\n",
       "357 2023-10-06 15:19:55   October    Friday\n",
       "358 2023-10-06 16:40:52   October    Friday\n",
       "359 2023-10-06 18:16:58   October    Friday\n",
       "360 2023-10-07 11:04:02   October  Saturday\n",
       "361 2023-10-07 12:05:24   October  Saturday\n",
       "\n",
       "[362 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file, drop the first row that holds the registiration IP only, drop the IP column and reset the indexing\n",
    "logs_fname = \"ip_logs.csv\"\n",
    "login_datetime_df = pd.read_csv(backup_data_path + logs_fname).rename(columns={\"date\": \"RawDate\"}).drop(index=0, columns=\"ip\").reset_index().drop(columns=\"index\")\n",
    "\n",
    "try:\n",
    "    raw_date_col = login_datetime_df[\"RawDate\"]  # Raw Date column\n",
    "\n",
    "    # Add new columns\n",
    "    login_datetime_df[[\"Date\", \"MonthName\", \"DayName\"]] = None\n",
    "    \n",
    "    for idx in range(len(raw_date_col)):\n",
    "        raw_date = raw_date_col.iloc[idx].replace(\" UTC\", \"\")  # Get the time in UTC time\n",
    "    \n",
    "        # Convert datetime to local time zone\n",
    "        local_datetime = change_datetime_zone(raw_date)\n",
    "        datetime_dict = raw_date_to_datetime(local_datetime)\n",
    "\n",
    "        # Insert items from datetime_dict to the new columns\n",
    "        for key in datetime_dict:\n",
    "            login_datetime_df.loc[idx, key] = datetime_dict[key]\n",
    "\n",
    "    login_datetime_df = login_datetime_df.drop(columns=\"RawDate\")\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "login_datetime_df[\"Date\"] = pd.to_datetime(login_datetime_df[\"Date\"])\n",
    "# login_datetime_df.to_csv(data_path + logs_fname, index=False)\n",
    "login_datetime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d44d3-fea5-4445-a518-2f5fb634ed22",
   "metadata": {},
   "source": [
    "## Post Votes\n",
    "\n",
    "This data includes the posts that I have voted. It includes an ID, the post link, and the type of the vote and through Reddit API it includes the total number of upvotes and downvotes, and the flair; however, no temporal data.  \n",
    "\n",
    "I will get the subreddit name from the URL, my vote and I will compare the sub to the subscribed subs data and get wheter or not I am subscribed to that subreddit currently.  \n",
    "\n",
    "Also, note that some of the posts are inaccesible due to different reasons which prevents data collection through Reddit API; therefore, there are some missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd39b5d-a173-44ab-929e-f86027666837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MyVote</th>\n",
       "      <th>UpvoteCount</th>\n",
       "      <th>DownvoteCount</th>\n",
       "      <th>Flair</th>\n",
       "      <th>SubredditName</th>\n",
       "      <th>IsSubscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unexpectedMontyPython</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>up</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>meme</td>\n",
       "      <td>ProgrammerHumor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>up</td>\n",
       "      <td>11978.0</td>\n",
       "      <td>902.0</td>\n",
       "      <td>meme</td>\n",
       "      <td>TheLastAirbender</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>up</td>\n",
       "      <td>152.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>risa</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unexpectedMontyPython</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>up</td>\n",
       "      <td>9443.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gaming</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>none</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ProgrammerHumor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>up</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seinfeld</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>up</td>\n",
       "      <td>188.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>meme</td>\n",
       "      <td>ProgrammerHumor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>up</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>humour</td>\n",
       "      <td>veYakinEvren</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1222 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MyVote  UpvoteCount  DownvoteCount   Flair          SubredditName  \\\n",
       "0        up          NaN            NaN     NaN  unexpectedMontyPython   \n",
       "1        up        196.0            2.0    meme        ProgrammerHumor   \n",
       "2        up      11978.0          902.0    meme       TheLastAirbender   \n",
       "3        up        152.0            9.0     NaN                   risa   \n",
       "4        up          NaN            NaN     NaN  unexpectedMontyPython   \n",
       "...     ...          ...            ...     ...                    ...   \n",
       "1217     up       9443.0          711.0     NaN                 gaming   \n",
       "1218   none          9.0            0.0     NaN        ProgrammerHumor   \n",
       "1219     up          8.0            1.0     NaN               seinfeld   \n",
       "1220     up        188.0            6.0    meme        ProgrammerHumor   \n",
       "1221     up         30.0            4.0  humour           veYakinEvren   \n",
       "\n",
       "      IsSubscribed  \n",
       "0             True  \n",
       "1             True  \n",
       "2             True  \n",
       "3             True  \n",
       "4             True  \n",
       "...            ...  \n",
       "1217          True  \n",
       "1218          True  \n",
       "1219          True  \n",
       "1220          True  \n",
       "1221          True  \n",
       "\n",
       "[1222 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file, rename the vote direction column and drop the id column.\n",
    "post_votes_fname = \"post_votes.csv\"\n",
    "post_votes_df = pd.read_csv(data_path + post_votes_fname).rename(columns={\"direction\": \"MyVote\", \"Upvotes\": \"UpvoteCount\", \"Downvotes\": \"DownvoteCount\"}).drop(columns=\"id\")\n",
    "\n",
    "# Add the new columns\n",
    "post_votes_df[[\"SubredditName\", \"IsSubscribed\"]] = None\n",
    "\n",
    "for idx in range(len(post_votes_df[\"permalink\"])):\n",
    "    post_vote_dict = {\"SubredditName\": None, \"IsSubscribed\": None}\n",
    "        \n",
    "    # Get the sub name from the link\n",
    "    permalink = post_votes_df.loc[idx, \"permalink\"]\n",
    "    start_idx = permalink.find(\"r/\") + 2\n",
    "    stop_idx = permalink.find(\"/\", start_idx)\n",
    "    sub_name = permalink[start_idx:stop_idx]\n",
    "    \n",
    "    # Add sub name to the corresponding place\n",
    "    post_votes_df.loc[idx, \"SubredditName\"] = sub_name\n",
    "\n",
    "    # Check if the sub is subscribed\n",
    "    post_votes_df.loc[idx, \"IsSubscribed\"] = is_subscribed_to(sub_name, subreddits_df)\n",
    "\n",
    "# Drop the permalink column\n",
    "post_votes_df = post_votes_df.drop(columns=\"permalink\")\n",
    "# Specify the Dtypes for later use\n",
    "post_votes_df[\"IsSubscribed\"] = post_votes_df[\"IsSubscribed\"].astype(dtype=\"bool\")\n",
    "# post_votes_df.to_csv(data_path + post_votes_fname, index=False)\n",
    "post_votes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57210e5-af6d-43ba-b568-5184332ad653",
   "metadata": {},
   "source": [
    "## Comment Votes  \n",
    "\n",
    "Comment votes is almost identical to the post votes data except that this includes the information about comments that I have voted instead of posts. Also through Reddit API it holds the score (or the net number of upvotes) instead of seperate counts of upvotes and downvotes.  \n",
    "\n",
    "I will perform the same cleaning as the post votes data: Remove the ID, get the subreddit name from the URL, my vote and I will compare the sub to the subscribed subs data and get wheter or not I am subscribed to that subreddit currently.  \n",
    "\n",
    "Also, note that some of the comments or their posts are inaccesible due to different reasons which prevents data collection through Reddit API; therefore, there are some missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a947319e-e27d-4086-8fe0-8e8d2e70bb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MyVote</th>\n",
       "      <th>Score</th>\n",
       "      <th>SubredditName</th>\n",
       "      <th>IsSubscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>up</td>\n",
       "      <td>2.0</td>\n",
       "      <td>GenP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>up</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flashcarts</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>up</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>ProgrammerHumor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>up</td>\n",
       "      <td>196.0</td>\n",
       "      <td>startrek</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>up</td>\n",
       "      <td>5.0</td>\n",
       "      <td>startrek</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>CodeBullet</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>up</td>\n",
       "      <td>1.0</td>\n",
       "      <td>montypython</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>none</td>\n",
       "      <td>37.0</td>\n",
       "      <td>seinfeld</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>up</td>\n",
       "      <td>11.0</td>\n",
       "      <td>TheLastAirbender</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>up</td>\n",
       "      <td>247.0</td>\n",
       "      <td>startrekmemes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MyVote   Score     SubredditName  IsSubscribed\n",
       "0       up     2.0              GenP         False\n",
       "1       up     1.0        flashcarts         False\n",
       "2       up  1190.0   ProgrammerHumor          True\n",
       "3       up   196.0          startrek          True\n",
       "4       up     5.0          startrek          True\n",
       "..     ...     ...               ...           ...\n",
       "255     up    35.0        CodeBullet          True\n",
       "256     up     1.0       montypython          True\n",
       "257   none    37.0          seinfeld          True\n",
       "258     up    11.0  TheLastAirbender          True\n",
       "259     up   247.0     startrekmemes          True\n",
       "\n",
       "[260 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file, rename the vote direction column and drop the id column.\n",
    "comment_votes_fname = \"comment_votes.csv\"\n",
    "comment_votes_df = pd.read_csv(data_path + comment_votes_fname).rename(columns={\"direction\": \"MyVote\"}).drop(columns=\"id\")\n",
    "\n",
    "# Add the new columns\n",
    "comment_votes_df[[\"SubredditName\", \"IsSubscribed\"]] = None\n",
    "\n",
    "for idx in range(len(comment_votes_df[\"permalink\"])):\n",
    "    comment_vote_dict = {\"SubredditName\": None, \"IsSubscribed\": None}\n",
    "        \n",
    "    # Get the sub name from the link\n",
    "    permalink = comment_votes_df.loc[idx, \"permalink\"]\n",
    "    start_idx = permalink.find(\"r/\") + 2\n",
    "    stop_idx = permalink.find(\"/\", start_idx)\n",
    "    sub_name = permalink[start_idx:stop_idx]\n",
    "\n",
    "    # Add sub name to the corresponding place\n",
    "    comment_votes_df.loc[idx, \"SubredditName\"] = sub_name\n",
    "\n",
    "    # Check if the sub is subscribed\n",
    "    comment_votes_df.loc[idx, \"IsSubscribed\"] = is_subscribed_to(sub_name, subreddits_df)\n",
    "\n",
    "# Drop the permalink column\n",
    "comment_votes_df = comment_votes_df.drop(columns=\"permalink\")\n",
    "# Specify the Dtypes for later use\n",
    "comment_votes_df[\"IsSubscribed\"] = comment_votes_df[\"IsSubscribed\"].astype(dtype=\"bool\")\n",
    "# comment_votes_df.to_csv(data_path + comment_votes_fname, index=False)\n",
    "comment_votes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e994b23-5f91-4b74-b4bb-b7ed3929d800",
   "metadata": {},
   "source": [
    "## Posts  \n",
    "\n",
    "The posts data is about the posts that I have created. It includes an ID, a permalink to the post, posting date, the IP that I have used, subreddit name that the post has been posted, and gildings and url data. Also the number of upvotes and downvotes, and the flair through Reddit API.  \n",
    "\n",
    "I will drop the permalink, IP, gildings, url and check if I am subscribed to the sub I have posted. I will keep the IDs to compare with the comments data later on.\n",
    "\n",
    "Also, note that some of the posts are inaccesible due to different reasons which prevents data collection through Reddit API; therefore, there are some missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d5e697-7c16-403c-8f38-4641f6acfb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Downvotes</th>\n",
       "      <th>Flair</th>\n",
       "      <th>IsSubscribed</th>\n",
       "      <th>Date</th>\n",
       "      <th>MonthName</th>\n",
       "      <th>DayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v7jv2a</td>\n",
       "      <td>consolerepair</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-06-08 10:38:39</td>\n",
       "      <td>June</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m3jkjt</td>\n",
       "      <td>NintendoDSi</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03-12 18:13:23</td>\n",
       "      <td>March</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10x881w</td>\n",
       "      <td>startrek</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-02-08 22:26:30</td>\n",
       "      <td>February</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126w0at</td>\n",
       "      <td>webdev</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-30 21:58:38</td>\n",
       "      <td>March</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r84lhi</td>\n",
       "      <td>flashcarts</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-03 20:40:55</td>\n",
       "      <td>December</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126w1tz</td>\n",
       "      <td>webdev</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-30 22:00:18</td>\n",
       "      <td>March</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15rhuzw</td>\n",
       "      <td>montypython</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-08-15 07:15:10</td>\n",
       "      <td>August</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16z0xzh</td>\n",
       "      <td>TheLastAirbender</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>meme violation</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-10-03 22:25:15</td>\n",
       "      <td>October</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10vxs5t</td>\n",
       "      <td>startrek</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-02-07 12:33:50</td>\n",
       "      <td>February</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zx3wgi</td>\n",
       "      <td>consolerepair</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-12-28 10:54:33</td>\n",
       "      <td>December</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rn2653</td>\n",
       "      <td>ElectroBOOM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>help</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-12-23 21:37:20</td>\n",
       "      <td>December</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2jlw8</td>\n",
       "      <td>veYakinEvren</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>question</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-01-22 11:40:40</td>\n",
       "      <td>January</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10y4z8s</td>\n",
       "      <td>startrekmemes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-02-09 23:17:33</td>\n",
       "      <td>February</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15s40td</td>\n",
       "      <td>startrekmemes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-08-15 23:26:54</td>\n",
       "      <td>August</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>z71esi</td>\n",
       "      <td>GenP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>question / discussion</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-11-28 19:47:25</td>\n",
       "      <td>November</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>r6iyed</td>\n",
       "      <td>flashcarts</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-01 19:39:12</td>\n",
       "      <td>December</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>v5baeg</td>\n",
       "      <td>flashcarts</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-05 14:19:07</td>\n",
       "      <td>June</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>m3fvca</td>\n",
       "      <td>consolerepair</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-03-12 14:43:51</td>\n",
       "      <td>March</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>m4n6zw</td>\n",
       "      <td>veYakinEvren</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>request</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-03-14 06:48:35</td>\n",
       "      <td>March</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15rhwx9</td>\n",
       "      <td>unexpectedpython</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-08-15 07:17:46</td>\n",
       "      <td>August</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11zivov</td>\n",
       "      <td>programmingmemes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-23 15:30:16</td>\n",
       "      <td>March</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jrkstt</td>\n",
       "      <td>pcbuilding</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-11-10 16:19:51</td>\n",
       "      <td>November</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mpvo09</td>\n",
       "      <td>DMAcademy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>need advice</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-04-13 08:11:16</td>\n",
       "      <td>April</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>162h83d</td>\n",
       "      <td>camphalfblood</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>question</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-08-27 08:03:09</td>\n",
       "      <td>August</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ta5da3</td>\n",
       "      <td>algorithms</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-03-09 14:00:09</td>\n",
       "      <td>March</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID         Subreddit  Upvotes  Downvotes                  Flair  \\\n",
       "0    v7jv2a     consolerepair      3.0        0.0                    NaN   \n",
       "1    m3jkjt       NintendoDSi      2.0        0.0                    NaN   \n",
       "2   10x881w          startrek      3.0        0.0                    NaN   \n",
       "3   126w0at            webdev      1.0        0.0                    NaN   \n",
       "4    r84lhi        flashcarts      2.0        0.0                    NaN   \n",
       "5   126w1tz            webdev      1.0        0.0                    NaN   \n",
       "6   15rhuzw       montypython     58.0        1.0                    NaN   \n",
       "7   16z0xzh  TheLastAirbender     13.0        3.0         meme violation   \n",
       "8   10vxs5t          startrek     11.0        3.0                    NaN   \n",
       "9    zx3wgi     consolerepair      2.0        0.0                    NaN   \n",
       "10   rn2653       ElectroBOOM      3.0        1.0                   help   \n",
       "11   l2jlw8      veYakinEvren      8.0        0.0               question   \n",
       "12  10y4z8s     startrekmemes      8.0        1.0                    NaN   \n",
       "13  15s40td     startrekmemes      1.0        0.0                    NaN   \n",
       "14   z71esi              GenP      0.0        0.0  question / discussion   \n",
       "15   r6iyed        flashcarts      7.0        0.0                    NaN   \n",
       "16   v5baeg        flashcarts      4.0        0.0                    NaN   \n",
       "17   m3fvca     consolerepair      1.0        0.0                    NaN   \n",
       "18   m4n6zw      veYakinEvren      1.0        0.0                request   \n",
       "19  15rhwx9  unexpectedpython     20.0        0.0                    NaN   \n",
       "20  11zivov  programmingmemes      4.0        0.0                    NaN   \n",
       "21   jrkstt        pcbuilding      1.0        0.0                    NaN   \n",
       "22   mpvo09         DMAcademy      1.0        0.0            need advice   \n",
       "23  162h83d     camphalfblood     29.0        0.0               question   \n",
       "24   ta5da3        algorithms      1.0        0.0                    NaN   \n",
       "\n",
       "    IsSubscribed                Date MonthName    DayName  \n",
       "0           True 2022-06-08 10:38:39      June  Wednesday  \n",
       "1          False 2021-03-12 18:13:23     March     Friday  \n",
       "2           True 2023-02-08 22:26:30  February  Wednesday  \n",
       "3          False 2023-03-30 21:58:38     March   Thursday  \n",
       "4          False 2021-12-03 20:40:55  December     Friday  \n",
       "5          False 2023-03-30 22:00:18     March   Thursday  \n",
       "6           True 2023-08-15 07:15:10    August    Tuesday  \n",
       "7           True 2023-10-03 22:25:15   October    Tuesday  \n",
       "8           True 2023-02-07 12:33:50  February    Tuesday  \n",
       "9           True 2022-12-28 10:54:33  December  Wednesday  \n",
       "10          True 2021-12-23 21:37:20  December   Thursday  \n",
       "11          True 2021-01-22 11:40:40   January     Friday  \n",
       "12          True 2023-02-09 23:17:33  February   Thursday  \n",
       "13          True 2023-08-15 23:26:54    August    Tuesday  \n",
       "14         False 2022-11-28 19:47:25  November     Monday  \n",
       "15         False 2021-12-01 19:39:12  December  Wednesday  \n",
       "16         False 2022-06-05 14:19:07      June     Sunday  \n",
       "17          True 2021-03-12 14:43:51     March     Friday  \n",
       "18          True 2021-03-14 06:48:35     March     Sunday  \n",
       "19          True 2023-08-15 07:17:46    August    Tuesday  \n",
       "20         False 2023-03-23 15:30:16     March   Thursday  \n",
       "21         False 2020-11-10 16:19:51  November    Tuesday  \n",
       "22          True 2021-04-13 08:11:16     April    Tuesday  \n",
       "23          True 2023-08-27 08:03:09    August     Sunday  \n",
       "24         False 2022-03-09 14:00:09     March  Wednesday  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file, rename the id, date, and subreddit columns and drop the permalink, ip, gildings, and url columns.\n",
    "posts_fname = \"post_headers.csv\"\n",
    "posts_df = pd.read_csv(data_path + posts_fname).rename(columns={\"id\": \"ID\", \"date\": \"RawDate\", \"subreddit\": \"Subreddit\"}).drop(columns=[\"permalink\", \"ip\", \"gildings\", \"url\"])\n",
    "\n",
    "try:\n",
    "    raw_date_col = posts_df[\"RawDate\"]  # Raw Date column\n",
    "\n",
    "    # Add new columns\n",
    "    posts_df[[\"IsSubscribed\", \"Date\", \"MonthName\", \"DayName\"]] = None\n",
    "    \n",
    "    for idx in range(len(raw_date_col)):\n",
    "        raw_date = raw_date_col.iloc[idx].replace(\" UTC\", \"\")  # Get the time in UTC time\n",
    "    \n",
    "        # Convert datetime to local time zone\n",
    "        local_datetime = change_datetime_zone(raw_date)\n",
    "        datetime_dict = raw_date_to_datetime(local_datetime)\n",
    "\n",
    "        # Insert items from datetime_dict to the new columns\n",
    "        for key in datetime_dict:\n",
    "            posts_df.loc[idx, key] = datetime_dict[key]\n",
    "        \n",
    "        # Check if subscribed\n",
    "        posts_df.loc[idx, \"IsSubscribed\"] = is_subscribed_to(posts_df.loc[idx, \"Subreddit\"], subreddits_df)\n",
    "    \n",
    "    posts_df = posts_df.drop(columns=\"RawDate\")\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "# Specify the Dtypes for later use\n",
    "posts_df[\"IsSubscribed\"] = posts_df[\"IsSubscribed\"].astype(dtype=\"bool\")\n",
    "posts_df[\"Date\"] = pd.to_datetime(posts_df[\"Date\"])\n",
    "# posts_df.to_csv(data_path + posts_fname, index=False)\n",
    "posts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ecdad-5e70-42cd-bd8c-299885699ec0",
   "metadata": {},
   "source": [
    "## Comments  \n",
    "\n",
    "Similar to the data about the posts, comments data also includes an ID, a permalink to the comment, comment date, the IP that I have used, subreddit name that the post that been commented has been posted, gildings, and net score through Reddit API. It does not include a url data like posts and it holds two extra information: a link to the parent object and _if the parent is posted by me_ an ID of the parent.  \n",
    "\n",
    "I will drop the permalink, IP, and gildings. I check if I am subscribed to the sub I have posted, and I will check if I own the parent and the posts.  \n",
    "\n",
    "Also, note that some of the comments or their posts are inaccesible due to different reasons which prevents data collection through Reddit API; therefore, there are some missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d80462f-d24e-47b1-8bfa-df078d297b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Score</th>\n",
       "      <th>IsSubscribed</th>\n",
       "      <th>Date</th>\n",
       "      <th>MonthName</th>\n",
       "      <th>DayName</th>\n",
       "      <th>IsParentOwned</th>\n",
       "      <th>IsPostOwned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j7jy563</td>\n",
       "      <td>startrek</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-02-07 12:42:58</td>\n",
       "      <td>February</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j7k0fm0</td>\n",
       "      <td>startrek</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-02-07 13:16:29</td>\n",
       "      <td>February</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jo77dm4</td>\n",
       "      <td>veYakinEvren</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-06-15 10:07:38</td>\n",
       "      <td>June</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jr1sd8q</td>\n",
       "      <td>veYakinEvren</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-07-07 20:33:12</td>\n",
       "      <td>July</td>\n",
       "      <td>Friday</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j7yb85s</td>\n",
       "      <td>gaming</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-02-10 10:06:23</td>\n",
       "      <td>February</td>\n",
       "      <td>Friday</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>jshmn5a</td>\n",
       "      <td>TheLastAirbender</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-07-18 21:58:33</td>\n",
       "      <td>July</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>jw8pa9d</td>\n",
       "      <td>tumblr</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-08-15 07:08:57</td>\n",
       "      <td>August</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>jxxbsqc</td>\n",
       "      <td>camphalfblood</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-08-27 08:47:22</td>\n",
       "      <td>August</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>jvey8c7</td>\n",
       "      <td>veYakinEvren</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-08-09 10:59:16</td>\n",
       "      <td>August</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>k0ekhtq</td>\n",
       "      <td>veYakinEvren</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-09-13 16:46:04</td>\n",
       "      <td>September</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         Subreddit  Score  IsSubscribed                Date  \\\n",
       "0    j7jy563          startrek      7          True 2023-02-07 12:42:58   \n",
       "1    j7k0fm0          startrek      4          True 2023-02-07 13:16:29   \n",
       "2    jo77dm4      veYakinEvren      1          True 2023-06-15 10:07:38   \n",
       "3    jr1sd8q      veYakinEvren      2          True 2023-07-07 20:33:12   \n",
       "4    j7yb85s            gaming      1          True 2023-02-10 10:06:23   \n",
       "..       ...               ...    ...           ...                 ...   \n",
       "117  jshmn5a  TheLastAirbender      3          True 2023-07-18 21:58:33   \n",
       "118  jw8pa9d            tumblr      1         False 2023-08-15 07:08:57   \n",
       "119  jxxbsqc     camphalfblood      3          True 2023-08-27 08:47:22   \n",
       "120  jvey8c7      veYakinEvren      3          True 2023-08-09 10:59:16   \n",
       "121  k0ekhtq      veYakinEvren      2          True 2023-09-13 16:46:04   \n",
       "\n",
       "     MonthName    DayName  IsParentOwned IsPostOwned  \n",
       "0     February    Tuesday          False        True  \n",
       "1     February    Tuesday          False       False  \n",
       "2         June   Thursday          False       False  \n",
       "3         July     Friday          False       False  \n",
       "4     February     Friday          False       False  \n",
       "..         ...        ...            ...         ...  \n",
       "117       July    Tuesday          False       False  \n",
       "118     August    Tuesday          False       False  \n",
       "119     August     Sunday          False        True  \n",
       "120     August  Wednesday          False       False  \n",
       "121  September  Wednesday          False       False  \n",
       "\n",
       "[122 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file, rename the id, date, and subreddit columns and drop the permalink, ip, and gildings columns.\n",
    "comments_fname = \"comment_headers.csv\"\n",
    "comments_df = pd.read_csv(data_path + comments_fname).rename(columns={\"id\": \"ID\", \"date\": \"RawDate\", \"subreddit\": \"Subreddit\"}).drop(columns=[\"permalink\", \"ip\", \"gildings\"])\n",
    "\n",
    "try:\n",
    "    raw_date_col = comments_df[\"RawDate\"]  # Raw Date column\n",
    "    \n",
    "    # Add new columns\n",
    "    comments_df[[\"IsSubscribed\", \"Date\", \"MonthName\", \"DayName\", \"IsParentOwned\", \"IsPostOwned\"]] = None\n",
    "    \n",
    "    for idx in range(len(raw_date_col)):\n",
    "        raw_date = raw_date_col.iloc[idx].replace(\" UTC\", \"\")  # Get the time in UTC time\n",
    "    \n",
    "        # Convert datetime to local time zone\n",
    "        local_datetime = change_datetime_zone(raw_date)\n",
    "        datetime_dict = raw_date_to_datetime(local_datetime)\n",
    "    \n",
    "        comments_dict = dict()\n",
    "        # Check if subscribed\n",
    "        comments_dict[\"IsSubscribed\"] = is_subscribed_to(comments_df.loc[idx, \"Subreddit\"], subreddits_df)\n",
    "\n",
    "        # Get the post id from the link, note that it does not have to be the parent id if it is reply to another comment\n",
    "        post_link = comments_df.loc[idx, \"link\"]\n",
    "        post_id_idx_start = post_link.find(\"comments/\") + 9\n",
    "        post_id_idx_end = post_link.find(\"/\", post_id_idx_start)\n",
    "        post_id = post_link[post_id_idx_start:post_id_idx_end]\n",
    "        # Check if the post is owned by me\n",
    "        comments_dict[\"IsPostOwned\"] = (posts_df == post_id).any().any()\n",
    "\n",
    "        # Check if parent ID exists, and if it does check if it is owned by me\n",
    "        if type(comments_df.loc[idx, \"parent\"]) == str:\n",
    "            parent_id = comments_df.loc[idx, \"parent\"]\n",
    "            comments_dict[\"IsParentOwned\"] = (posts_df == parent_id).any().any() or (comments_df[\"ID\"] == parent_id).any()\n",
    "        else:\n",
    "            comments_dict[\"IsParentOwned\"] = False\n",
    "        \n",
    "        # Combine datetime_dict and comments_dict\n",
    "        comments_dict = comments_dict | datetime_dict\n",
    "\n",
    "        # Insert items from comments_dict to the new columns\n",
    "        for key in comments_dict:\n",
    "            comments_df.loc[idx, key] = comments_dict[key]\n",
    "    \n",
    "    comments_df = comments_df.drop(columns=[\"RawDate\", \"parent\", \"link\"])\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "# Specify the Dtypes for later use\n",
    "comments_df[\"IsSubscribed\"] = comments_df[\"IsSubscribed\"].astype(dtype=\"bool\")\n",
    "comments_df[\"IsParentOwned\"] = comments_df[\"IsParentOwned\"].astype(dtype=\"bool\")\n",
    "comments_df[\"Date\"] = pd.to_datetime(comments_df[\"Date\"])\n",
    "# comments_df.to_csv(data_path + comments_fname, index=False)\n",
    "comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad937100-ba12-4aeb-a0cf-8a7119b76ab9",
   "metadata": {},
   "source": [
    "# Data Visiualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags and Flairs\n",
    "\n",
    "I will count and visualize the tags and flairs of the subreddits that I am subscribed to. It is worth to note that while tags have no missing data since they are annotated by hand, flairs have missing data since some of the subreddits do not have flairs or they have a poor flair system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2b2b0d-1ba9-462c-a5a6-37692239af94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-5a003b18b1dd4ab28bd9b620fb56e2a0.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-5a003b18b1dd4ab28bd9b620fb56e2a0.vega-embed details,\n",
       "  #altair-viz-5a003b18b1dd4ab28bd9b620fb56e2a0.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-5a003b18b1dd4ab28bd9b620fb56e2a0\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-5a003b18b1dd4ab28bd9b620fb56e2a0\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-5a003b18b1dd4ab28bd9b620fb56e2a0\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.15.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.15.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"stroke\": null}, \"axisX\": {\"domainColor\": \"#000\", \"domainWidth\": 2, \"grid\": false, \"labelFontSize\": 13}, \"axisY\": {\"domain\": false, \"labelFontSize\": 14, \"titleFontSize\": 18}, \"padding\": {\"left\": 15, \"right\": 15, \"top\": 15, \"bottom\": 15}, \"title\": {\"fontSize\": 18}}, \"data\": {\"name\": \"data-794bc7e66ae3fd20382acc58cdfcc7d9\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"value\": \"#1f77b4\"}, \"tooltip\": [{\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"tickCount\": 6.0}, \"field\": \"Count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Flair\", \"sort\": \"-x\", \"title\": null, \"type\": \"nominal\"}}, \"height\": 333.33, \"title\": \"Flairs\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.15.1.json\", \"datasets\": {\"data-794bc7e66ae3fd20382acc58cdfcc7d9\": [{\"Flair\": \"meme\", \"Count\": 9}, {\"Flair\": \"video idea\", \"Count\": 2}, {\"Flair\": \"other\", \"Count\": 4}, {\"Flair\": \"art\", \"Count\": 2}, {\"Flair\": \"resource\", \"Count\": 4}, {\"Flair\": \"discussion\", \"Count\": 12}, {\"Flair\": \"help\", \"Count\": 3}, {\"Flair\": \"fan art\", \"Count\": 5}, {\"Flair\": \"question\", \"Count\": 8}, {\"Flair\": \"image\", \"Count\": 3}, {\"Flair\": \"video\", \"Count\": 2}, {\"Flair\": \"fanfiction\", \"Count\": 2}, {\"Flair\": \"headcanon\", \"Count\": 2}, {\"Flair\": \"cosplay\", \"Count\": 3}, {\"Flair\": \"theory\", \"Count\": 2}, {\"Flair\": \"quote\", \"Count\": 2}, {\"Flair\": \"miscellaneous\", \"Count\": 2}, {\"Flair\": \"meta\", \"Count\": 3}, {\"Flair\": \"news\", \"Count\": 7}, {\"Flair\": \"tutorial\", \"Count\": 4}, {\"Flair\": \"guide\", \"Count\": 2}, {\"Flair\": \"bug\", \"Count\": 2}, {\"Flair\": \"review\", \"Count\": 3}, {\"Flair\": \"article\", \"Count\": 2}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of each tag from the tags column of the subreddits_df\n",
    "if \"Tags\" in subreddits_df.columns:\n",
    "    tag_count_dict = dict()\n",
    "    tags_col = subreddits_df[\"Tags\"]\n",
    "    for idx in range(len(tags_col)):\n",
    "        tags = tags_col.iloc[idx].split(\", \")\n",
    "        for tag in tags:\n",
    "            if tag in tag_count_dict:\n",
    "                tag_count_dict[tag] += 1\n",
    "            else:\n",
    "                tag_count_dict[tag] = 1\n",
    "    tag_count_df = pd.DataFrame({\"Tag\": list(tag_count_dict.keys()), \"Count\": list(tag_count_dict.values())})\n",
    "    tag_count_df[\"Tag\"] = tag_count_df[\"Tag\"].astype(dtype=\"category\")\n",
    "\n",
    "    # Create the chart for tags\n",
    "    chart1 = alt.Chart(tag_count_df).mark_bar().encode(\n",
    "        alt.X(\"Count:Q\", axis=alt.Axis(tickCount=tag_count_df[\"Count\"].max() // 2)),\n",
    "        alt.Y(\"Tag:N\", sort=\"-x\", title=None),\n",
    "        color=alt.value(\"#1f77b4\"),\n",
    "        tooltip=[\"Count:Q\"],  # Show the count when hovering over the bar\n",
    "    ).properties(\n",
    "        # Set the size of the chart\n",
    "        width=500,\n",
    "        height=333.33,\n",
    "        title = \"Tags\"\n",
    "    )\n",
    "else:\n",
    "    chart1 = None\n",
    "\n",
    "\n",
    "# Count the number of each flair from the flairs column of the subreddits_df\n",
    "flair_count_dict = dict()\n",
    "flairs_col = subreddits_df[\"Flairs\"]\n",
    "for idx in range(len(flairs_col)):\n",
    "    if type(flairs_col.iloc[idx]) != str:\n",
    "        continue\n",
    "    flairs = flairs_col.iloc[idx].split(\", \")\n",
    "    for flair in flairs:\n",
    "        if flair in flair_count_dict:\n",
    "            flair_count_dict[flair] += 1\n",
    "        else:\n",
    "            flair_count_dict[flair] = 1\n",
    "flair_count_df = pd.DataFrame({\"Flair\": list(flair_count_dict.keys()), \"Count\": list(flair_count_dict.values())})\n",
    "flair_count_df[\"Flair\"] = flair_count_df[\"Flair\"].astype(dtype=\"category\")\n",
    "# Drop flairs with less than 2 counts since it means they are unique for subreddit\n",
    "flair_count_df = flair_count_df[flair_count_df[\"Count\"] > 1]\n",
    "\n",
    "# Create the chart for flairs\n",
    "chart2 = alt.Chart(flair_count_df).mark_bar().encode(\n",
    "    alt.X(\"Count:Q\", axis=alt.Axis(tickCount=flair_count_df[\"Count\"].max() // 2)),\n",
    "    alt.Y(\"Flair:N\", sort=\"-x\", title=None),\n",
    "    color=alt.value(\"#1f77b4\"),\n",
    "    tooltip=[\"Count:Q\"],  # Show the count when hovering over the bar\n",
    ").properties(\n",
    "    # Set the size of the chart\n",
    "    width=500,\n",
    "    height=333.33,\n",
    "    title = \"Flairs\"\n",
    ")\n",
    "\n",
    "if chart1 is not None:\n",
    "    # Combine the charts\n",
    "    chart = alt.hconcat(chart1, chart2, spacing=120)\n",
    "else:\n",
    "    chart = chart2\n",
    "\n",
    "# Add paddings to HConcatChart object\n",
    "chart = chart.configure(\n",
    "    padding={\"left\": 15, \"right\": 15, \"top\": 15, \"bottom\": 15},\n",
    "    title={\"fontSize\": 18},\n",
    ").configure_view(\n",
    "    stroke=None,\n",
    ").configure_axisX(\n",
    "    labelFontSize=13,\n",
    "    grid=False,  # Remove the grid\n",
    "    domainWidth=2,  # Set the width of the axis line\n",
    "    domainColor=\"#000\"  # Set the color of the axis line\n",
    ").configure_axisY(\n",
    "    labelFontSize=14,\n",
    "    titleFontSize=18,\n",
    "    domain=False,  # Remove the axis line\n",
    ")\n",
    "\n",
    "if chart1 is not None:\n",
    "    chart1.save(\"figures/tags_and_flairs/altair_tags.html\")\n",
    "    chart1.save(\"figures/tags_and_flairs/altair_tags.png\")\n",
    "    chart2.save(\"figures/tags_and_flairs/altair_flairs.html\")\n",
    "    chart2.save(\"figures/tags_and_flairs/altair_flairs.png\")\n",
    "    chart.save(\"figures/tags_and_flairs/altair_tags_flairs.html\")\n",
    "    chart.save(\"figures/tags_and_flairs/altair_tags_flairs.png\")\n",
    "else:\n",
    "    chart2.save(\"figures/tags_and_flairs/altair_flairs.html\")\n",
    "    chart2.save(\"figures/tags_and_flairs/altair_flairs.png\")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will count the logins in 30 minute intervals and visualize in bar chart to see at what times I am active.  \n",
    "\n",
    "For the code I round (floor) the minutes to 30 minute intervals and count the logins. But for the _histograms_ to function properly I need a data including all the intervals even if there are no logins in that interval. Therefore, I will create a new dataframe with all the intervals, combine with my data, count the logins and offset everything by 1 to get the correct counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3f67b56a2cb043c18da79c1eebf3da65.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3f67b56a2cb043c18da79c1eebf3da65.vega-embed details,\n",
       "  #altair-viz-3f67b56a2cb043c18da79c1eebf3da65.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3f67b56a2cb043c18da79c1eebf3da65\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3f67b56a2cb043c18da79c1eebf3da65\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3f67b56a2cb043c18da79c1eebf3da65\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.15.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.15.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-43fdbe35a48251bde563e44fae85b4a6\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"tickCount\": 48}, \"field\": \"Time\", \"title\": \"Time\", \"type\": \"ordinal\"}, \"y\": {\"axis\": {\"tickCount\": 15.0}, \"field\": \"count\", \"title\": \"Count\", \"type\": \"quantitative\"}}, \"title\": \"Total Logins by Time\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.15.1.json\", \"datasets\": {\"data-43fdbe35a48251bde563e44fae85b4a6\": [{\"Time\": \"21:00\", \"count\": 15}, {\"Time\": \"13:00\", \"count\": 14}, {\"Time\": \"20:00\", \"count\": 14}, {\"Time\": \"08:00\", \"count\": 13}, {\"Time\": \"08:30\", \"count\": 13}, {\"Time\": \"14:30\", \"count\": 13}, {\"Time\": \"11:00\", \"count\": 13}, {\"Time\": \"15:30\", \"count\": 12}, {\"Time\": \"12:30\", \"count\": 12}, {\"Time\": \"10:30\", \"count\": 12}, {\"Time\": \"19:00\", \"count\": 12}, {\"Time\": \"09:30\", \"count\": 11}, {\"Time\": \"16:00\", \"count\": 11}, {\"Time\": \"11:30\", \"count\": 10}, {\"Time\": \"20:30\", \"count\": 10}, {\"Time\": \"15:00\", \"count\": 10}, {\"Time\": \"13:30\", \"count\": 10}, {\"Time\": \"21:30\", \"count\": 10}, {\"Time\": \"17:00\", \"count\": 10}, {\"Time\": \"12:00\", \"count\": 10}, {\"Time\": \"16:30\", \"count\": 10}, {\"Time\": \"07:30\", \"count\": 10}, {\"Time\": \"10:00\", \"count\": 9}, {\"Time\": \"18:30\", \"count\": 9}, {\"Time\": \"07:00\", \"count\": 9}, {\"Time\": \"18:00\", \"count\": 9}, {\"Time\": \"22:30\", \"count\": 8}, {\"Time\": \"09:00\", \"count\": 7}, {\"Time\": \"14:00\", \"count\": 7}, {\"Time\": \"17:30\", \"count\": 7}, {\"Time\": \"19:30\", \"count\": 6}, {\"Time\": \"23:00\", \"count\": 6}, {\"Time\": \"22:00\", \"count\": 5}, {\"Time\": \"23:30\", \"count\": 4}, {\"Time\": \"04:00\", \"count\": 4}, {\"Time\": \"02:30\", \"count\": 3}, {\"Time\": \"06:30\", \"count\": 2}, {\"Time\": \"05:30\", \"count\": 2}, {\"Time\": \"02:00\", \"count\": 2}, {\"Time\": \"01:30\", \"count\": 2}, {\"Time\": \"00:00\", \"count\": 2}, {\"Time\": \"00:30\", \"count\": 1}, {\"Time\": \"06:00\", \"count\": 1}, {\"Time\": \"03:00\", \"count\": 1}, {\"Time\": \"01:00\", \"count\": 1}, {\"Time\": \"05:00\", \"count\": 0}, {\"Time\": \"04:30\", \"count\": 0}, {\"Time\": \"03:30\", \"count\": 0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from datetime import timedelta\n",
    "# Round time to closest 10 minutes\n",
    "login_datetime_rounded_df = login_datetime_df.copy()[[\"Date\", \"DayName\"]]\n",
    "login_datetime_rounded_df[\"Date\"] = login_datetime_rounded_df[\"Date\"].apply(lambda x: floor_dt(x, 30))\n",
    "\n",
    "total = login_datetime_rounded_df.copy()\n",
    "time_range = pd.date_range(start=\"00:00\", end=\"23:59\", freq=\"30min\").strftime(\"%H:%M\")\n",
    "time_df = pd.DataFrame({\"Time\": time_range})\n",
    "total[\"Time\"] = total[\"Date\"].dt.strftime(\"%H:%M\")\n",
    "# Concat the time_df and group_time\n",
    "total = pd.concat([time_df, total], axis=0).reset_index().drop(columns=\"index\")\n",
    "# Count the number of each time\n",
    "total = total.value_counts(subset=[\"Time\"]).reset_index()\n",
    "# Offset counts by 1\n",
    "total[\"count\"] = total[\"count\"] - 1\n",
    "\n",
    "# Create the chart\n",
    "chart = alt.Chart(total).mark_bar().encode(\n",
    "    x=alt.X(\"Time:O\", title=\"Time\", axis=alt.Axis(tickCount=48)),\n",
    "    y=alt.Y(\"count:Q\", title=\"Count\", axis=alt.Axis(tickCount=total[\"count\"].max())),\n",
    "    tooltip=[\"count:Q\"],\n",
    ").properties(\n",
    "    title=\"Total Logins by Time\",\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-02d1cc93f95549a0a164e71f25343539.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-02d1cc93f95549a0a164e71f25343539.vega-embed details,\n",
       "  #altair-viz-02d1cc93f95549a0a164e71f25343539.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-02d1cc93f95549a0a164e71f25343539\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-02d1cc93f95549a0a164e71f25343539\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-02d1cc93f95549a0a164e71f25343539\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.15.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.15.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300, \"stroke\": null}, \"axisX\": {\"domainColor\": \"#000\", \"domainWidth\": 2, \"grid\": false, \"labelFontSize\": 13}, \"axisY\": {\"domain\": false, \"labelFontSize\": 14, \"titleFontSize\": 18}, \"padding\": {\"left\": 15, \"right\": 15, \"top\": 15, \"bottom\": 15}, \"title\": {\"fontSize\": 18}}, \"vconcat\": [{\"data\": {\"name\": \"data-2235c9b7270b4c7fd0dd411ed5408268\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"tickCount\": 48}, \"field\": \"Time\", \"title\": \"Time\", \"type\": \"ordinal\"}, \"y\": {\"axis\": {\"tickCount\": 5.0}, \"field\": \"count\", \"title\": \"Count\", \"type\": \"quantitative\"}}, \"title\": \"Monday\"}, {\"data\": {\"name\": \"data-600a82188aabc0352edb386394585131\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"tickCount\": 48}, \"field\": \"Time\", \"title\": \"Time\", \"type\": \"ordinal\"}, \"y\": {\"axis\": {\"tickCount\": 5.0}, \"field\": \"count\", \"title\": \"Count\", \"type\": \"quantitative\"}}, \"title\": \"Tuesday\"}, {\"data\": {\"name\": \"data-b256bf777ac37296067fe5f8e6731fad\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"tickCount\": 48}, \"field\": \"Time\", \"title\": \"Time\", \"type\": \"ordinal\"}, \"y\": {\"axis\": {\"tickCount\": 4.0}, \"field\": \"count\", \"title\": \"Count\", \"type\": \"quantitative\"}}, \"title\": \"Wednesday\"}, {\"data\": {\"name\": \"data-7848a261bf204ecd7f36a331c8ca2b3d\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"tickCount\": 48}, \"field\": \"Time\", \"title\": \"Time\", \"type\": \"ordinal\"}, \"y\": {\"axis\": {\"tickCount\": 5.0}, \"field\": \"count\", \"title\": \"Count\", \"type\": \"quantitative\"}}, \"title\": \"Thursday\"}, {\"data\": {\"name\": \"data-ccea3d412b1b6fa9dcda685991a14e47\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"tickCount\": 48}, \"field\": \"Time\", \"title\": \"Time\", \"type\": \"ordinal\"}, \"y\": {\"axis\": {\"tickCount\": 5.0}, \"field\": \"count\", \"title\": \"Count\", \"type\": \"quantitative\"}}, \"title\": \"Friday\"}, {\"data\": {\"name\": \"data-ce5cb271a24d66c2c11a5a6128104b8d\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"tickCount\": 48}, \"field\": \"Time\", \"title\": \"Time\", \"type\": \"ordinal\"}, \"y\": {\"axis\": {\"tickCount\": 5.0}, \"field\": \"count\", \"title\": \"Count\", \"type\": \"quantitative\"}}, \"title\": \"Saturday\"}, {\"data\": {\"name\": \"data-6f79a511e7a1d4ea8c47b162c3ec424a\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"count\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"tickCount\": 48}, \"field\": \"Time\", \"title\": \"Time\", \"type\": \"ordinal\"}, \"y\": {\"axis\": {\"tickCount\": 5.0}, \"field\": \"count\", \"title\": \"Count\", \"type\": \"quantitative\"}}, \"title\": \"Sunday\"}], \"spacing\": 10, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.15.1.json\", \"datasets\": {\"data-2235c9b7270b4c7fd0dd411ed5408268\": [{\"Time\": \"20:00\", \"count\": 5}, {\"Time\": \"12:00\", \"count\": 4}, {\"Time\": \"08:00\", \"count\": 4}, {\"Time\": \"18:30\", \"count\": 3}, {\"Time\": \"13:00\", \"count\": 3}, {\"Time\": \"11:00\", \"count\": 3}, {\"Time\": \"16:00\", \"count\": 3}, {\"Time\": \"22:30\", \"count\": 2}, {\"Time\": \"17:00\", \"count\": 2}, {\"Time\": \"10:00\", \"count\": 2}, {\"Time\": \"15:30\", \"count\": 2}, {\"Time\": \"18:00\", \"count\": 1}, {\"Time\": \"06:00\", \"count\": 1}, {\"Time\": \"14:30\", \"count\": 1}, {\"Time\": \"14:00\", \"count\": 1}, {\"Time\": \"22:00\", \"count\": 1}, {\"Time\": \"03:00\", \"count\": 1}, {\"Time\": \"12:30\", \"count\": 1}, {\"Time\": \"00:30\", \"count\": 1}, {\"Time\": \"17:30\", \"count\": 1}, {\"Time\": \"08:30\", \"count\": 1}, {\"Time\": \"21:00\", \"count\": 1}, {\"Time\": \"09:30\", \"count\": 1}, {\"Time\": \"09:00\", \"count\": 1}, {\"Time\": \"02:00\", \"count\": 1}, {\"Time\": \"07:00\", \"count\": 1}, {\"Time\": \"19:00\", \"count\": 1}, {\"Time\": \"21:30\", \"count\": 0}, {\"Time\": \"20:30\", \"count\": 0}, {\"Time\": \"23:00\", \"count\": 0}, {\"Time\": \"16:30\", \"count\": 0}, {\"Time\": \"19:30\", \"count\": 0}, {\"Time\": \"00:00\", \"count\": 0}, {\"Time\": \"15:00\", \"count\": 0}, {\"Time\": \"13:30\", \"count\": 0}, {\"Time\": \"11:30\", \"count\": 0}, {\"Time\": \"10:30\", \"count\": 0}, {\"Time\": \"07:30\", \"count\": 0}, {\"Time\": \"06:30\", \"count\": 0}, {\"Time\": \"05:30\", \"count\": 0}, {\"Time\": \"05:00\", \"count\": 0}, {\"Time\": \"04:30\", \"count\": 0}, {\"Time\": \"04:00\", \"count\": 0}, {\"Time\": \"03:30\", \"count\": 0}, {\"Time\": \"02:30\", \"count\": 0}, {\"Time\": \"01:30\", \"count\": 0}, {\"Time\": \"01:00\", \"count\": 0}, {\"Time\": \"23:30\", \"count\": 0}], \"data-600a82188aabc0352edb386394585131\": [{\"Time\": \"21:30\", \"count\": 5}, {\"Time\": \"14:30\", \"count\": 4}, {\"Time\": \"16:30\", \"count\": 3}, {\"Time\": \"23:00\", \"count\": 3}, {\"Time\": \"13:30\", \"count\": 3}, {\"Time\": \"21:00\", \"count\": 3}, {\"Time\": \"11:00\", \"count\": 3}, {\"Time\": \"10:30\", \"count\": 3}, {\"Time\": \"06:30\", \"count\": 2}, {\"Time\": \"14:00\", \"count\": 2}, {\"Time\": \"15:00\", \"count\": 2}, {\"Time\": \"07:30\", \"count\": 2}, {\"Time\": \"07:00\", \"count\": 2}, {\"Time\": \"12:00\", \"count\": 2}, {\"Time\": \"12:30\", \"count\": 2}, {\"Time\": \"18:30\", \"count\": 2}, {\"Time\": \"19:30\", \"count\": 2}, {\"Time\": \"20:00\", \"count\": 2}, {\"Time\": \"17:30\", \"count\": 1}, {\"Time\": \"16:00\", \"count\": 1}, {\"Time\": \"15:30\", \"count\": 1}, {\"Time\": \"18:00\", \"count\": 1}, {\"Time\": \"20:30\", \"count\": 1}, {\"Time\": \"22:30\", \"count\": 1}, {\"Time\": \"13:00\", \"count\": 1}, {\"Time\": \"23:30\", \"count\": 1}, {\"Time\": \"10:00\", \"count\": 1}, {\"Time\": \"09:30\", \"count\": 1}, {\"Time\": \"09:00\", \"count\": 1}, {\"Time\": \"08:30\", \"count\": 1}, {\"Time\": \"11:30\", \"count\": 1}, {\"Time\": \"00:30\", \"count\": 0}, {\"Time\": \"03:30\", \"count\": 0}, {\"Time\": \"01:00\", \"count\": 0}, {\"Time\": \"01:30\", \"count\": 0}, {\"Time\": \"22:00\", \"count\": 0}, {\"Time\": \"02:00\", \"count\": 0}, {\"Time\": \"02:30\", \"count\": 0}, {\"Time\": \"03:00\", \"count\": 0}, {\"Time\": \"04:30\", \"count\": 0}, {\"Time\": \"04:00\", \"count\": 0}, {\"Time\": \"19:00\", \"count\": 0}, {\"Time\": \"05:00\", \"count\": 0}, {\"Time\": \"05:30\", \"count\": 0}, {\"Time\": \"17:00\", \"count\": 0}, {\"Time\": \"06:00\", \"count\": 0}, {\"Time\": \"08:00\", \"count\": 0}, {\"Time\": \"00:00\", \"count\": 0}], \"data-b256bf777ac37296067fe5f8e6731fad\": [{\"Time\": \"10:30\", \"count\": 4}, {\"Time\": \"07:30\", \"count\": 4}, {\"Time\": \"12:30\", \"count\": 3}, {\"Time\": \"13:00\", \"count\": 3}, {\"Time\": \"08:00\", \"count\": 3}, {\"Time\": \"02:30\", \"count\": 3}, {\"Time\": \"14:30\", \"count\": 3}, {\"Time\": \"09:30\", \"count\": 2}, {\"Time\": \"15:30\", \"count\": 2}, {\"Time\": \"00:00\", \"count\": 2}, {\"Time\": \"18:30\", \"count\": 2}, {\"Time\": \"01:30\", \"count\": 2}, {\"Time\": \"16:30\", \"count\": 1}, {\"Time\": \"20:00\", \"count\": 1}, {\"Time\": \"20:30\", \"count\": 1}, {\"Time\": \"14:00\", \"count\": 1}, {\"Time\": \"21:00\", \"count\": 1}, {\"Time\": \"22:00\", \"count\": 1}, {\"Time\": \"13:30\", \"count\": 1}, {\"Time\": \"22:30\", \"count\": 1}, {\"Time\": \"17:00\", \"count\": 1}, {\"Time\": \"12:00\", \"count\": 1}, {\"Time\": \"01:00\", \"count\": 1}, {\"Time\": \"08:30\", \"count\": 1}, {\"Time\": \"11:00\", \"count\": 0}, {\"Time\": \"18:00\", \"count\": 0}, {\"Time\": \"23:00\", \"count\": 0}, {\"Time\": \"02:00\", \"count\": 0}, {\"Time\": \"21:30\", \"count\": 0}, {\"Time\": \"03:00\", \"count\": 0}, {\"Time\": \"03:30\", \"count\": 0}, {\"Time\": \"04:00\", \"count\": 0}, {\"Time\": \"19:30\", \"count\": 0}, {\"Time\": \"19:00\", \"count\": 0}, {\"Time\": \"04:30\", \"count\": 0}, {\"Time\": \"17:30\", \"count\": 0}, {\"Time\": \"11:30\", \"count\": 0}, {\"Time\": \"05:00\", \"count\": 0}, {\"Time\": \"05:30\", \"count\": 0}, {\"Time\": \"16:00\", \"count\": 0}, {\"Time\": \"06:00\", \"count\": 0}, {\"Time\": \"15:00\", \"count\": 0}, {\"Time\": \"06:30\", \"count\": 0}, {\"Time\": \"07:00\", \"count\": 0}, {\"Time\": \"09:00\", \"count\": 0}, {\"Time\": \"10:00\", \"count\": 0}, {\"Time\": \"00:30\", \"count\": 0}, {\"Time\": \"23:30\", \"count\": 0}], \"data-7848a261bf204ecd7f36a331c8ca2b3d\": [{\"Time\": \"21:00\", \"count\": 5}, {\"Time\": \"16:00\", \"count\": 3}, {\"Time\": \"15:30\", \"count\": 3}, {\"Time\": \"09:30\", \"count\": 3}, {\"Time\": \"11:30\", \"count\": 3}, {\"Time\": \"15:00\", \"count\": 2}, {\"Time\": \"17:00\", \"count\": 2}, {\"Time\": \"08:00\", \"count\": 2}, {\"Time\": \"22:30\", \"count\": 2}, {\"Time\": \"13:00\", \"count\": 1}, {\"Time\": \"16:30\", \"count\": 1}, {\"Time\": \"13:30\", \"count\": 1}, {\"Time\": \"11:00\", \"count\": 1}, {\"Time\": \"10:30\", \"count\": 1}, {\"Time\": \"10:00\", \"count\": 1}, {\"Time\": \"14:00\", \"count\": 1}, {\"Time\": \"12:30\", \"count\": 1}, {\"Time\": \"23:30\", \"count\": 1}, {\"Time\": \"08:30\", \"count\": 1}, {\"Time\": \"07:00\", \"count\": 1}, {\"Time\": \"17:30\", \"count\": 1}, {\"Time\": \"18:30\", \"count\": 1}, {\"Time\": \"19:30\", \"count\": 1}, {\"Time\": \"20:00\", \"count\": 1}, {\"Time\": \"20:30\", \"count\": 1}, {\"Time\": \"21:30\", \"count\": 1}, {\"Time\": \"22:00\", \"count\": 1}, {\"Time\": \"07:30\", \"count\": 1}, {\"Time\": \"18:00\", \"count\": 0}, {\"Time\": \"19:00\", \"count\": 0}, {\"Time\": \"23:00\", \"count\": 0}, {\"Time\": \"00:00\", \"count\": 0}, {\"Time\": \"14:30\", \"count\": 0}, {\"Time\": \"00:30\", \"count\": 0}, {\"Time\": \"09:00\", \"count\": 0}, {\"Time\": \"06:30\", \"count\": 0}, {\"Time\": \"06:00\", \"count\": 0}, {\"Time\": \"05:30\", \"count\": 0}, {\"Time\": \"05:00\", \"count\": 0}, {\"Time\": \"04:30\", \"count\": 0}, {\"Time\": \"04:00\", \"count\": 0}, {\"Time\": \"03:30\", \"count\": 0}, {\"Time\": \"03:00\", \"count\": 0}, {\"Time\": \"02:30\", \"count\": 0}, {\"Time\": \"02:00\", \"count\": 0}, {\"Time\": \"01:30\", \"count\": 0}, {\"Time\": \"01:00\", \"count\": 0}, {\"Time\": \"12:00\", \"count\": 0}], \"data-ccea3d412b1b6fa9dcda685991a14e47\": [{\"Time\": \"19:00\", \"count\": 5}, {\"Time\": \"08:30\", \"count\": 4}, {\"Time\": \"16:30\", \"count\": 4}, {\"Time\": \"17:00\", \"count\": 3}, {\"Time\": \"20:30\", \"count\": 3}, {\"Time\": \"20:00\", \"count\": 3}, {\"Time\": \"18:00\", \"count\": 3}, {\"Time\": \"07:00\", \"count\": 3}, {\"Time\": \"15:30\", \"count\": 2}, {\"Time\": \"13:00\", \"count\": 2}, {\"Time\": \"13:30\", \"count\": 2}, {\"Time\": \"15:00\", \"count\": 2}, {\"Time\": \"23:30\", \"count\": 2}, {\"Time\": \"10:30\", \"count\": 2}, {\"Time\": \"17:30\", \"count\": 2}, {\"Time\": \"21:30\", \"count\": 2}, {\"Time\": \"14:00\", \"count\": 1}, {\"Time\": \"18:30\", \"count\": 1}, {\"Time\": \"19:30\", \"count\": 1}, {\"Time\": \"12:30\", \"count\": 1}, {\"Time\": \"11:00\", \"count\": 1}, {\"Time\": \"12:00\", \"count\": 1}, {\"Time\": \"10:00\", \"count\": 1}, {\"Time\": \"04:00\", \"count\": 1}, {\"Time\": \"09:30\", \"count\": 1}, {\"Time\": \"08:00\", \"count\": 1}, {\"Time\": \"23:00\", \"count\": 0}, {\"Time\": \"22:30\", \"count\": 0}, {\"Time\": \"22:00\", \"count\": 0}, {\"Time\": \"01:00\", \"count\": 0}, {\"Time\": \"21:00\", \"count\": 0}, {\"Time\": \"01:30\", \"count\": 0}, {\"Time\": \"02:00\", \"count\": 0}, {\"Time\": \"02:30\", \"count\": 0}, {\"Time\": \"03:00\", \"count\": 0}, {\"Time\": \"03:30\", \"count\": 0}, {\"Time\": \"04:30\", \"count\": 0}, {\"Time\": \"11:30\", \"count\": 0}, {\"Time\": \"05:00\", \"count\": 0}, {\"Time\": \"05:30\", \"count\": 0}, {\"Time\": \"16:00\", \"count\": 0}, {\"Time\": \"06:00\", \"count\": 0}, {\"Time\": \"06:30\", \"count\": 0}, {\"Time\": \"14:30\", \"count\": 0}, {\"Time\": \"07:30\", \"count\": 0}, {\"Time\": \"09:00\", \"count\": 0}, {\"Time\": \"00:30\", \"count\": 0}, {\"Time\": \"00:00\", \"count\": 0}], \"data-ce5cb271a24d66c2c11a5a6128104b8d\": [{\"Time\": \"11:30\", \"count\": 5}, {\"Time\": \"14:30\", \"count\": 4}, {\"Time\": \"11:00\", \"count\": 3}, {\"Time\": \"18:00\", \"count\": 3}, {\"Time\": \"15:00\", \"count\": 3}, {\"Time\": \"20:30\", \"count\": 2}, {\"Time\": \"13:30\", \"count\": 2}, {\"Time\": \"10:00\", \"count\": 2}, {\"Time\": \"13:00\", \"count\": 2}, {\"Time\": \"09:00\", \"count\": 2}, {\"Time\": \"09:30\", \"count\": 2}, {\"Time\": \"04:00\", \"count\": 2}, {\"Time\": \"22:00\", \"count\": 2}, {\"Time\": \"15:30\", \"count\": 2}, {\"Time\": \"23:00\", \"count\": 2}, {\"Time\": \"17:30\", \"count\": 1}, {\"Time\": \"12:30\", \"count\": 1}, {\"Time\": \"16:00\", \"count\": 1}, {\"Time\": \"12:00\", \"count\": 1}, {\"Time\": \"08:30\", \"count\": 1}, {\"Time\": \"17:00\", \"count\": 1}, {\"Time\": \"08:00\", \"count\": 1}, {\"Time\": \"07:30\", \"count\": 1}, {\"Time\": \"07:00\", \"count\": 1}, {\"Time\": \"19:00\", \"count\": 1}, {\"Time\": \"19:30\", \"count\": 1}, {\"Time\": \"05:30\", \"count\": 1}, {\"Time\": \"20:00\", \"count\": 1}, {\"Time\": \"21:00\", \"count\": 1}, {\"Time\": \"21:30\", \"count\": 1}, {\"Time\": \"02:00\", \"count\": 1}, {\"Time\": \"16:30\", \"count\": 1}, {\"Time\": \"18:30\", \"count\": 0}, {\"Time\": \"22:30\", \"count\": 0}, {\"Time\": \"00:00\", \"count\": 0}, {\"Time\": \"14:00\", \"count\": 0}, {\"Time\": \"00:30\", \"count\": 0}, {\"Time\": \"10:30\", \"count\": 0}, {\"Time\": \"06:30\", \"count\": 0}, {\"Time\": \"06:00\", \"count\": 0}, {\"Time\": \"05:00\", \"count\": 0}, {\"Time\": \"04:30\", \"count\": 0}, {\"Time\": \"03:30\", \"count\": 0}, {\"Time\": \"03:00\", \"count\": 0}, {\"Time\": \"02:30\", \"count\": 0}, {\"Time\": \"01:30\", \"count\": 0}, {\"Time\": \"01:00\", \"count\": 0}, {\"Time\": \"23:30\", \"count\": 0}], \"data-6f79a511e7a1d4ea8c47b162c3ec424a\": [{\"Time\": \"19:00\", \"count\": 5}, {\"Time\": \"21:00\", \"count\": 4}, {\"Time\": \"08:30\", \"count\": 4}, {\"Time\": \"16:00\", \"count\": 3}, {\"Time\": \"12:30\", \"count\": 3}, {\"Time\": \"09:00\", \"count\": 3}, {\"Time\": \"13:00\", \"count\": 2}, {\"Time\": \"11:00\", \"count\": 2}, {\"Time\": \"10:30\", \"count\": 2}, {\"Time\": \"10:00\", \"count\": 2}, {\"Time\": \"07:30\", \"count\": 2}, {\"Time\": \"08:00\", \"count\": 2}, {\"Time\": \"20:30\", \"count\": 2}, {\"Time\": \"22:30\", \"count\": 2}, {\"Time\": \"05:30\", \"count\": 1}, {\"Time\": \"11:30\", \"count\": 1}, {\"Time\": \"17:30\", \"count\": 1}, {\"Time\": \"15:00\", \"count\": 1}, {\"Time\": \"14:30\", \"count\": 1}, {\"Time\": \"14:00\", \"count\": 1}, {\"Time\": \"13:30\", \"count\": 1}, {\"Time\": \"23:00\", \"count\": 1}, {\"Time\": \"18:00\", \"count\": 1}, {\"Time\": \"12:00\", \"count\": 1}, {\"Time\": \"21:30\", \"count\": 1}, {\"Time\": \"09:30\", \"count\": 1}, {\"Time\": \"04:00\", \"count\": 1}, {\"Time\": \"20:00\", \"count\": 1}, {\"Time\": \"17:00\", \"count\": 1}, {\"Time\": \"19:30\", \"count\": 1}, {\"Time\": \"07:00\", \"count\": 1}, {\"Time\": \"18:30\", \"count\": 0}, {\"Time\": \"22:00\", \"count\": 0}, {\"Time\": \"00:00\", \"count\": 0}, {\"Time\": \"16:30\", \"count\": 0}, {\"Time\": \"15:30\", \"count\": 0}, {\"Time\": \"00:30\", \"count\": 0}, {\"Time\": \"06:30\", \"count\": 0}, {\"Time\": \"06:00\", \"count\": 0}, {\"Time\": \"05:00\", \"count\": 0}, {\"Time\": \"04:30\", \"count\": 0}, {\"Time\": \"03:30\", \"count\": 0}, {\"Time\": \"03:00\", \"count\": 0}, {\"Time\": \"02:30\", \"count\": 0}, {\"Time\": \"02:00\", \"count\": 0}, {\"Time\": \"01:30\", \"count\": 0}, {\"Time\": \"01:00\", \"count\": 0}, {\"Time\": \"23:30\", \"count\": 0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Group by day\n",
    "login_datetime_grouped = login_datetime_rounded_df.groupby(\"DayName\")\n",
    "\n",
    "# Create the charts for each day\n",
    "charts = {}\n",
    "for name, group in login_datetime_grouped:\n",
    "    time_range = pd.date_range(start=\"00:00\", end=\"23:59\", freq=\"30min\").strftime(\"%H:%M\")\n",
    "    time_df = pd.DataFrame({\"Time\": time_range})\n",
    "    group[\"Time\"] = group[\"Date\"].dt.strftime(\"%H:%M\")\n",
    "    # Concat the time_df and group_time\n",
    "    group = pd.concat([time_df, group], axis=0).reset_index().drop(columns=\"index\")\n",
    "    # Count the number of each time\n",
    "    group = group.value_counts(subset=[\"Time\"]).reset_index()\n",
    "    # Offset counts by 1\n",
    "    group[\"count\"] = group[\"count\"] - 1\n",
    "\n",
    "    # Create the chart\n",
    "    chart = alt.Chart(group).mark_bar().encode(\n",
    "        x=alt.X(\"Time:O\", title=\"Time\", axis=alt.Axis(tickCount=48)),\n",
    "        y=alt.Y(\"count:Q\", title=\"Count\", axis=alt.Axis(tickCount=group[\"count\"].max())),\n",
    "        tooltip=[\"count:Q\"],\n",
    "    ).properties(\n",
    "        title=name\n",
    "    )\n",
    "    charts[name] = chart\n",
    "\n",
    "# Sort the charts by day in week order\n",
    "charts_list = [charts[\"Monday\"], charts[\"Tuesday\"], charts[\"Wednesday\"], charts[\"Thursday\"], charts[\"Friday\"], charts[\"Saturday\"], charts[\"Sunday\"]]\n",
    "# Combine the charts\n",
    "chart = alt.vconcat(*charts_list, spacing=10)\n",
    "\n",
    "chart = chart.configure(\n",
    "    padding={\"left\": 15, \"right\": 15, \"top\": 15, \"bottom\": 15},\n",
    "    title={\"fontSize\": 18},\n",
    ").configure_view(\n",
    "    stroke=None,\n",
    ").configure_axisX(\n",
    "    labelFontSize=13,\n",
    "    grid=False,  # Remove the grid\n",
    "    domainWidth=2,  # Set the width of the axis line\n",
    "    domainColor=\"#000\"  # Set the color of the axis line\n",
    ").configure_axisY(\n",
    "    labelFontSize=14,\n",
    "    titleFontSize=18,\n",
    "    domain=False,  # Remove the axis line\n",
    ")\n",
    "\n",
    "# Save the charts\n",
    "for name, ch in charts.items():\n",
    "    ch.save(f\"figures/login_times/altair_{name}.html\")\n",
    "    ch.save(f\"figures/login_times/altair_{name}.png\")\n",
    "chart.save(\"figures/login_times/altair_login_times.html\")\n",
    "\n",
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
